{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"73e2f1e7-57a8-4116-a0f3-7a6637721474","_uuid":"b3428ba1-c216-48b5-8369-af60f773bdc0","trusted":true},"source":["# Prep"]},{"cell_type":"markdown","metadata":{},"source":["## Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"36b89dd9-4fa4-4495-9622-70c42f332691","_uuid":"388b54a7-e452-42e6-960e-9238afcc338b","collapsed":false,"execution":{"iopub.execute_input":"2022-08-10T10:55:13.446580Z","iopub.status.busy":"2022-08-10T10:55:13.445780Z","iopub.status.idle":"2022-08-10T10:55:22.504868Z","shell.execute_reply":"2022-08-10T10:55:22.503989Z","shell.execute_reply.started":"2022-08-10T10:55:13.446541Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["!pip install torchsummary"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-10T10:55:22.508279Z","iopub.status.busy":"2022-08-10T10:55:22.507984Z","iopub.status.idle":"2022-08-10T10:55:22.515647Z","shell.execute_reply":"2022-08-10T10:55:22.514789Z","shell.execute_reply.started":"2022-08-10T10:55:22.508247Z"},"trusted":true},"outputs":[],"source":["import os\n","import time\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","import torchsummary\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as TF\n","from torch.utils.data import DataLoader, Dataset, ConcatDataset, WeightedRandomSampler\n","from torchsummary import summary\n","from torchvision.io import read_image\n","from collections import Counter\n","\n","import numpy as np\n","from PIL import ImageStat"]},{"cell_type":"markdown","metadata":{"_cell_guid":"e4f1bd72-da14-4776-bc3f-baebf5c59915","_uuid":"53f44730-7ae6-4466-a41f-1bb7860e7e0f","trusted":true},"source":["## Hyperparameter Settings -- variables to be tweaked"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ed2f92ae-e42a-4828-a002-66ea16ec9cc8","_uuid":"64307f12-9710-45c5-8ab2-d6fa01eb9139","collapsed":false,"execution":{"iopub.execute_input":"2022-08-10T10:55:22.517812Z","iopub.status.busy":"2022-08-10T10:55:22.517287Z","iopub.status.idle":"2022-08-10T10:55:22.527887Z","shell.execute_reply":"2022-08-10T10:55:22.527112Z","shell.execute_reply.started":"2022-08-10T10:55:22.517776Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# Model architecture parameter\n","# Available architectures\n","# resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110'\n","# 'vgg19', 'alexnet', \n","# 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152'\n","arch = 'resnet20'\n","resize = [32,32]\n","\n","# Learning parameters\n","weight_decay = 1e-4            # (1e-4 - float?) Weight decay\n","momentum = 0.9                  # (0.9 - dec) Learning momentum\n","lr = 0.01                        # (0.1 - dec) Learning rate\n","start_epoch = 0                 # (0 - int) First epoch value\n","epochs = 50                    # (200 - int) How many epochs\n","batch_size_train = 64           # (64 - int) Size of batches\n","batch_size_val = 64             # (64 - int) Size of load batches\n","grayscale = False\n","\n","# Performance optimizations\n","half = False                    # (0 - bool) Use half-precision (16-bit)\n","num_workers = 2                 # Set to 2 for Kaggle\n","\n","# Trained model parameters\n","evaluate = False                # (0 - bool) evaluate model\n","pretrained = False              # (0 - bool) evaluate pretrained model\n","print_freq = 999                # (999 - int) print frequency\n","\n","# Input/Output parameters\n","save_every = 10                # (10 - int) save checkpoint intervals\n","\n","# ('save_temp' - string) The directory used to save the trained models\n","save_dir = 'save_temp'\n","\n","do_normalize = False\n","if grayscale:\n","    normalize_gray = transforms.Normalize(mean=0.6587, std=0.2029)\n","else:\n","    normalize_rgb = transforms.Normalize(mean=[0.7914, 0.6591, 0.4151], std=[0.1208, 0.1548, 0.1494])"]},{"cell_type":"markdown","metadata":{"_cell_guid":"93e3b9e6-ae10-42bf-9af5-3515f8262f24","_uuid":"068fd8c3-f4be-4f47-b597-68e4c75f3f67","trusted":true},"source":["# Resnet Architecture for small image datasets (i.e. CIFAR-10, Sundanese Lontar Character Set)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"11d87ef4-0413-4bcc-ba16-ce7067804183","_uuid":"365e27af-ed11-41b4-9d51-ff0cfd498b56","trusted":true},"source":["Contains resnet20, resnet32, resnet44, resnet56, resnet110, resnet1202*"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2438761-654a-4457-89ad-81fb8986eeb7","_uuid":"bee11f70-acc5-4fbf-95fd-402594b7c458","collapsed":false,"execution":{"iopub.execute_input":"2022-08-10T10:55:22.530809Z","iopub.status.busy":"2022-08-10T10:55:22.530409Z","iopub.status.idle":"2022-08-10T10:55:26.495644Z","shell.execute_reply":"2022-08-10T10:55:26.494188Z","shell.execute_reply.started":"2022-08-10T10:55:22.530771Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["__all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110', \n","           'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', \n","           'vgg19', 'alexnet']\n","\n","\n","def _weights_init(m):\n","    classname = m.__class__.__name__\n","    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n","        init.kaiming_normal_(m.weight)\n","\n","\n","class LambdaLayer(nn.Module):\n","    def __init__(self, lambd):\n","        super(LambdaLayer, self).__init__()\n","        self.lambd = lambd\n","\n","    def forward(self, x):\n","        return self.lambd(x)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1, option='A'):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(\n","            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != planes:\n","            if option == 'A':\n","                '''\n","                For CIFAR10 ResNet paper uses option A.\n","                '''\n","                self.shortcut = LambdaLayer(lambda x:\n","                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n","            elif option == 'B':\n","                self.shortcut = nn.Sequential(\n","                    nn.Conv2d(in_planes, self.expansion * planes,\n","                              kernel_size=1, stride=stride, bias=False),\n","                    nn.BatchNorm2d(self.expansion * planes)\n","                )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=28):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 16\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n","        self.linear = nn.Linear(64, num_classes)\n","        self.apply(_weights_init)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = F.avg_pool2d(out, out.size()[3])\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def resnet20():\n","    return ResNet(BasicBlock, [3, 3, 3])\n","\n","def resnet32():\n","    return ResNet(BasicBlock, [5, 5, 5])\n","\n","def resnet44():\n","    return ResNet(BasicBlock, [7, 7, 7])\n","\n","def resnet56():\n","    return ResNet(BasicBlock, [9, 9, 9])\n","\n","def resnet110():\n","    return ResNet(BasicBlock, [18, 18, 18])\n","\n","# predefined architectures from torchvision\n","\n","def vgg19():\n","    return models.vgg19()\n","\n","def alexnet():\n","    return models.alexnet()\n","\n","def resnet18():\n","    return models.resnet18()\n","\n","def resnet34():\n","    return models.resnet34()\n","\n","def resnet50():\n","    return models.resnet50()\n","\n","def resnet101():\n","    return models.resnet101()\n","\n","def resnet152():\n","    return models.resnet152()\n","\n","def test(net):\n","    import numpy as np\n","    total_params = 0\n","\n","    for x in filter(lambda p: p.requires_grad, net.parameters()):\n","        total_params += np.prod(x.data.numpy().shape)\n","    print(\"Total number of params\", total_params)\n","    print(\"Total layers\", len(list(filter(\n","        lambda p: p.requires_grad and len(p.data.size()) > 1, net.parameters()))))\n","\n","\n","if __name__ == \"__main__\":\n","    for net_name in __all__:\n","        if net_name.startswith('resnet'):\n","            print(net_name)\n","            test(globals()[net_name]())\n","            print()\n","    \n","archfunc = eval(arch + \"()\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2324cbd-d0a3-4f3b-9a95-b26653a7b63a","_uuid":"8563e8fb-3fb0-4e59-8d26-4da0f819884d","collapsed":false,"execution":{"iopub.execute_input":"2022-08-10T10:55:26.497265Z","iopub.status.busy":"2022-08-10T10:55:26.497018Z","iopub.status.idle":"2022-08-10T10:55:26.541973Z","shell.execute_reply":"2022-08-10T10:55:26.541225Z","shell.execute_reply.started":"2022-08-10T10:55:26.497231Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = archfunc.to(device)\n","\n","\n","if grayscale:\n","    self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1, bias=False)\n","    summary(model, (1, 32, 32))\n","else:\n","    summary(model, (3, 32, 32))\n","    \n","best_prec1 = 0\n","best_prec5 = 0"]},{"cell_type":"markdown","metadata":{"_cell_guid":"82edb1fa-cfb8-474b-8671-70567718bf9c","_uuid":"17b83b22-1aab-42a6-859a-6e4ba40f66a1","trusted":true},"source":["# Training and Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e84e646-b1f3-4aa4-8e2d-9062ebf31d1e","_uuid":"f10235ae-7649-41d3-8e73-aa5834198065","collapsed":false,"execution":{"iopub.execute_input":"2022-08-10T10:55:26.544808Z","iopub.status.busy":"2022-08-10T10:55:26.544616Z","iopub.status.idle":"2022-08-10T10:55:26.555838Z","shell.execute_reply":"2022-08-10T10:55:26.553993Z","shell.execute_reply.started":"2022-08-10T10:55:26.544785Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def train(train_loader, model, criterion, optimizer, epoch):\n","    '''\n","    Run one train epoch\n","    '''\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","    top5 = AverageMeter()\n","\n","    # switch to train mode\n","    model.train()\n","\n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","\n","        target = target.cuda()\n","        input_var = input.cuda()\n","        target_var = target\n","        if half:\n","            input_var = input_var.half()\n","\n","        # compute output\n","        output = model(input_var)\n","        loss = criterion(output, target_var)\n","\n","        \n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n","        optimizer.step()\n","\n","        output = output.float()\n","        loss = loss.float()\n","\n","        # measure accuracy and record loss\n","        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n","        losses.update(loss.item(), input.size(0))\n","        top1.update(prec1.item(), input.size(0))\n","        top5.update(prec5.item(), input.size(0))\n","        \n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % print_freq == 0:\n","            print('Epoch: [{0}][{1}/{2}] | '\n","                  'Loss {loss.val:.4f} ({loss.avg:.4f}) | '\n","                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f}) | '\n","                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n","                      epoch, i, len(train_loader), batch_time=batch_time,\n","                      data_time=data_time, loss=losses, top1=top1, top5=top5))\n","        \n","    return losses.val"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4cf47f1b-6b3f-4d04-90d8-cf69a33e0688","_uuid":"6dd44da6-d9d6-4846-bb2f-23ee6f7e2602","collapsed":false,"execution":{"iopub.execute_input":"2022-08-10T10:55:26.557500Z","iopub.status.busy":"2022-08-10T10:55:26.557174Z","iopub.status.idle":"2022-08-10T10:55:26.568715Z","shell.execute_reply":"2022-08-10T10:55:26.567965Z","shell.execute_reply.started":"2022-08-10T10:55:26.557467Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def validate(val_loader, model, criterion):\n","    '''\n","    Run evaluation\n","    '''\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","    top5 = AverageMeter()\n","\n","    # switch to evaluate mode\n","    model.eval()\n","\n","    end = time.time()\n","    with torch.no_grad():\n","        for i, (input, target) in enumerate(val_loader):\n","            target = target.cuda()\n","            input_var = input.cuda()\n","            target_var = target.cuda()\n","\n","            if half:\n","                input_var = input_var.half()\n","\n","            # compute output\n","            output = model(input_var)\n","            loss = criterion(output, target_var)\n","\n","            output = output.float()\n","            loss = loss.float()\n","\n","            # measure accuracy and record loss\n","            prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n","            losses.update(loss.item(), input.size(0))\n","            top1.update(prec1.item(), input.size(0))\n","            top5.update(prec5.item(), input.size(0))\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","    print('Test\\t  Prec@1: {top1.avg:.3f} (Err: {error1:.3f} )\\n'\n","          'Test\\t  Prec@5: {top5.avg:.3f} (Err: {error5:.3f} )'\n","          .format(top1=top1, error1=100-top1.avg, top5=top5, error5=100-top5.avg))\n","\n","    return top1.avg, top5.avg\n","\n","\n","def save_checkpoint(state, filename='checkpoint.th'):\n","    '''\n","    Save the training model\n","    '''\n","    torch.save(state, filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc39e40f-d419-4207-b299-a21b0644d007","_uuid":"8a2124f9-a6fe-4d82-bf39-4d903e7162a9","collapsed":false,"execution":{"iopub.execute_input":"2022-08-10T10:55:26.570437Z","iopub.status.busy":"2022-08-10T10:55:26.570195Z","iopub.status.idle":"2022-08-10T10:55:26.581997Z","shell.execute_reply":"2022-08-10T10:55:26.581116Z","shell.execute_reply.started":"2022-08-10T10:55:26.570407Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class AverageMeter(object):\n","    '''Computes and stores the average and current value'''\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","class IterationCounter(object):\n","    def __init__(self):\n","        self.reset()\n","        \n","    def reset(self):\n","        self.count = 0\n","        \n","    def update(self, val, n=1):\n","        self.count += n\n","\n","def accuracy(output, target, topk=(1,)):\n","    '''Computes the precision@k for the specified values of k'''\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].reshape(-1).float().sum(0)\n","        res.append(correct_k.mul_(100.0 / batch_size))\n","    return res"]},{"cell_type":"markdown","metadata":{"_cell_guid":"01738983-007d-4c6e-bc5c-23c8ed2dd6ee","_uuid":"3c3bd9a0-fbcc-428a-87cc-480a8ee58efb","trusted":true},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-10T10:55:26.583599Z","iopub.status.busy":"2022-08-10T10:55:26.583294Z","iopub.status.idle":"2022-08-10T10:55:26.593414Z","shell.execute_reply":"2022-08-10T10:55:26.592634Z","shell.execute_reply.started":"2022-08-10T10:55:26.583566Z"},"trusted":true},"outputs":[],"source":["class LontarDataset(Dataset):\n","    def __init__(self,\n","                 annotations_file='../input/sundanese-lontar-character-dataset/train_labels.csv',\n","                 img_dir='../input/sundanese-lontar-character-dataset/train_image',\n","                 transform=None,\n","                 target_transform=None\n","                 ):\n","        self.img_labels = pd.read_csv(annotations_file)\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n","        image = read_image(img_path)\n","        label = self.img_labels.iloc[idx, 1]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","\n","        return (image, label)"]},{"cell_type":"markdown","metadata":{},"source":["## Data Balancing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-10T10:55:26.596957Z","iopub.status.busy":"2022-08-10T10:55:26.596593Z","iopub.status.idle":"2022-08-10T10:55:26.614013Z","shell.execute_reply":"2022-08-10T10:55:26.613358Z","shell.execute_reply.started":"2022-08-10T10:55:26.596906Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('../input/sundanese-lontar-character-dataset/train_labels.csv')\n","labels = np.array(df.values.tolist())\n","classes = labels[:,1].astype(int)\n","class_sample_count = np.array(\n","    [\n","        len(np.where(labels == t)[0]) for t in np.unique(labels[:,1])\n","    ])\n","weight = 1. / class_sample_count\n","samples_weight = np.array([weight[t] for t in classes])\n","sampler = WeightedRandomSampler(samples_weight, len(samples_weight))"]},{"cell_type":"markdown","metadata":{},"source":["## Functional Transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-10T10:55:26.615301Z","iopub.status.busy":"2022-08-10T10:55:26.615077Z","iopub.status.idle":"2022-08-10T10:55:26.621215Z","shell.execute_reply":"2022-08-10T10:55:26.620480Z","shell.execute_reply.started":"2022-08-10T10:55:26.615267Z"},"trusted":true},"outputs":[],"source":["class GaussBlur(object):\n","    def __init__(self, sigma=1):\n","        self.sigma = sigma\n","    \n","    def __call__(self, x):\n","        return TF.gaussian_blur(x, self.sigma)\n","    \n","class ThresholdTransform(object):\n","    def __init__(self, threshold):\n","        self.thr = threshold / 255.  # input threshold for [0..255] gray level, convert to [0..1]\n","\n","    def __call__(self, x):\n","        return (x > self.thr).to(x.dtype)  # do not change the data type\n"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset & Dataloaders"]},{"cell_type":"markdown","metadata":{},"source":["### Mean and Standard Deviation of the dataset\n","(kind of a quick and dirty solution)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.execute_input":"2022-08-10T10:55:26.623569Z","iopub.status.busy":"2022-08-10T10:55:26.622848Z","iopub.status.idle":"2022-08-10T10:55:42.846570Z","shell.execute_reply":"2022-08-10T10:55:42.845634Z","shell.execute_reply.started":"2022-08-10T10:55:26.623530Z"},"trusted":true},"outputs":[],"source":["def get_mean_and_std(dataloader):\n","    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n","    for data, _ in dataloader:\n","        # Mean over batch, height and width, but not over the channels\n","        if grayscale:\n","            channels_sum += torch.mean(data)\n","            channels_squared_sum += torch.mean(data**2)\n","        else:\n","            channels_sum += torch.mean(data, dim=[0, 2, 3])\n","            channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n","            \n","        num_batches += 1\n","        \n","    mean = channels_sum / num_batches\n","\n","    # std = sqrt(E[X^2] - (E[X])^2)\n","    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n","\n","    return mean, std\n","\n","transforms_norm_rgb = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor()\n","    ]\n","\n","transforms_norm_rgb_ac = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.RandomAutocontrast(p=1.0)\n","    ]\n","\n","transforms_norm_rgb_gauss = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    GaussBlur()\n","    ]\n","\n","transforms_norm_rgb_ac_gauss = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.RandomAutocontrast(p=1.0),\n","    GaussBlur()\n","    ]\n","\n","transforms_norm_gray = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.Grayscale()\n","    ]\n","\n","transforms_norm_gray_ac = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.Grayscale(),\n","    transforms.RandomAutocontrast(p=1.0)\n","    ]\n","\n","transforms_norm_gray_gauss = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.Grayscale(),\n","    GaussBlur()\n","    ]\n","\n","transforms_norm_gray_ac_gauss = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.Grayscale(),\n","    transforms.RandomAutocontrast(p=1.0),\n","    GaussBlur()\n","    ]\n","\n","transforms_composes = [transforms_norm_rgb, transforms_norm_rgb_ac, transforms_norm_rgb_gauss, transforms_norm_rgb_ac_gauss, transforms_norm_gray, transforms_norm_gray_ac, transforms_norm_gray_gauss, transforms_norm_gray_ac_gauss]\n","\n","for transforms_compose in transforms_composes:\n","    train_data_norm = LontarDataset(transform=transforms.Compose(transforms_compose))\n","    train_loader_norm = DataLoader(dataset=train_data_norm, batch_size=len(train_data_norm), num_workers=num_workers)\n","    dataset_mean, dataset_std = get_mean_and_std(train_loader_norm)\n","    print(f\"mean={dataset_mean}, std={dataset_std}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-10T10:55:42.848873Z","iopub.status.busy":"2022-08-10T10:55:42.848511Z","iopub.status.idle":"2022-08-10T10:55:42.891342Z","shell.execute_reply":"2022-08-10T10:55:42.890590Z","shell.execute_reply.started":"2022-08-10T10:55:42.848824Z"},"trusted":true},"outputs":[],"source":["transforms_compose = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    ]\n","\n","transforms_compose_test = [\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    ]\n","\n","if do_normalize:\n","    transforms_compose.append(normalize)\n","    transforms_compose_test.append(normalize)\n","    \n","if grayscale:\n","    transforms_compose.append(transforms.Grayscale())\n","    transforms_compose_test.append(transforms.Grayscale())\n","\n","print(transforms_compose)\n","    \n","train_data = LontarDataset(transform=transforms.Compose(transforms_compose))\n","\n","test_data = datasets.ImageFolder(\n","    root='../input/sundanese-lontar-character-dataset/test_image',\n","    transform=transforms.Compose(transforms_compose_test))   \n","\n","train_loader = DataLoader(dataset=train_data, batch_size=batch_size_train,\n","                          num_workers=num_workers, pin_memory=True, sampler=sampler)\n","test_loader = DataLoader(dataset=test_data, batch_size=batch_size_val,\n","                         shuffle=False, num_workers=num_workers, pin_memory=True)\n","val_loader = DataLoader(dataset=test_data, batch_size=batch_size_val,\n","                        shuffle=True, num_workers=num_workers, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2022-08-10T10:55:42.894064Z","iopub.status.busy":"2022-08-10T10:55:42.892698Z","iopub.status.idle":"2022-08-10T10:55:42.916542Z","shell.execute_reply":"2022-08-10T10:55:42.915802Z","shell.execute_reply.started":"2022-08-10T10:55:42.894027Z"},"trusted":true},"outputs":[],"source":["transforms_rgb = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    ]\n","\n","transforms_rgb_norm = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.7914, 0.6591, 0.4151], std=[0.1208, 0.1548, 0.1494])\n","    ]\n","\n","transforms_rgb_ac = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.RandomAutocontrast(p=1.0)\n","    ]\n","\n","transforms_rgb_ac_normalize = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.RandomAutocontrast(p=1.0),\n","    transforms.Normalize(mean=[0.7431, 0.6549, 0.5137], std=[0.2067, 0.2260, 0.2094])\n","    ]\n","    \n","transforms_rgb_gauss = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    GaussBlur()\n","    ]\n","\n","transforms_rgb_gauss_norm = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    GaussBlur(),\n","    transforms.Normalize(mean=[0.7914, 0.6591, 0.4151], std=[0.1208, 0.1548, 0.1494])\n","    ]\n","    \n","transforms_rgb_ac_gauss = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.RandomAutocontrast(p=1.0),\n","    GaussBlur()\n","    ]\n","\n","transforms_rgb_ac_gauss_normalize = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.RandomAutocontrast(p=1.0),\n","    GaussBlur(),\n","    transforms.Normalize(mean=[0.7431, 0.6549, 0.5137], std=[0.2067, 0.2260, 0.2094])\n","    ]\n","\n","################################################################\n","\n","transforms_gray = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.Grayscale()\n","    ]\n","\n","transforms_gray_norm = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.6708], std=[0.1418]),\n","    transforms.Grayscale()\n","    ]\n","\n","transforms_gray_ac = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.RandomAutocontrast(p=1.0),\n","    transforms.Grayscale()\n","    ]\n","\n","transforms_gray_ac_normalize = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.RandomAutocontrast(p=1.0),\n","    transforms.Normalize(mean=[0.6652], std=[0.2174]),\n","    transforms.Grayscale()\n","    ]\n","    \n","transforms_gray_gauss = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    GaussBlur(),\n","    transforms.Grayscale()\n","    ]\n","\n","transforms_gray_gauss_norm = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    GaussBlur(),\n","    transforms.Normalize(mean=[0.6708], std=[0.1418]),\n","    transforms.Grayscale()\n","    ]\n","    \n","transforms_gray_ac_gauss = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.RandomAutocontrast(p=1.0),\n","    GaussBlur(),\n","    transforms.Grayscale()\n","    ]\n","\n","transforms_gray_ac_gauss_normalize = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.RandomAutocontrast(p=1.0),\n","    GaussBlur(),\n","    transforms.Normalize(mean=[0.6652], std=[0.2174]),\n","    transforms.Grayscale()\n","    ]\n","\n","transforms_gray_ac_binary = [\n","    transforms.ToPILImage(),\n","    transforms.Resize(resize),\n","    transforms.ToTensor(),\n","    transforms.RandomAutocontrast(p=1.0),\n","    GaussBlur(),\n","    transforms.Normalize(mean=[0.6652], std=[0.2174]),\n","    transforms.Grayscale(),\n","    ThresholdTransform(threshold=169.6303609013557455)\n","    ]\n","    \n","transforms_composes_data = [\n","    transforms_rgb,\n","    transforms_rgb_norm,\n","    transforms_rgb_ac,\n","    transforms_rgb_ac_normalize,\n","    transforms_rgb_gauss,\n","    transforms_rgb_gauss_norm,\n","    transforms_rgb_ac_gauss,\n","    transforms_rgb_ac_gauss_normalize,\n","    transforms_gray,\n","    transforms_gray_norm,\n","    transforms_gray_ac,\n","    transforms_gray_ac_normalize,\n","    transforms_gray_gauss,\n","    transforms_gray_gauss_norm,\n","    transforms_gray_ac_gauss,\n","    transforms_gray_ac_gauss_normalize,\n","    transforms_gray_ac_binary\n","    ]"]},{"cell_type":"markdown","metadata":{},"source":["### Test Output"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"69aed9fb-ede7-4c64-8545-3b4b4334d0ac","_uuid":"ab96d02d-d821-43bb-9343-9daf04aa6444","collapsed":false,"execution":{"iopub.execute_input":"2022-08-10T10:55:42.919749Z","iopub.status.busy":"2022-08-10T10:55:42.919534Z","iopub.status.idle":"2022-08-10T10:55:54.885958Z","shell.execute_reply":"2022-08-10T10:55:54.884867Z","shell.execute_reply.started":"2022-08-10T10:55:42.919724Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# load classes from a txt file\n","classes_file = open(\n","    '../input/sundanese-lontar-character-dataset/list_class_name.txt', 'r')\n","classes = [(line.strip()).split() for line in classes_file]\n","classes_file.close()\n","\n","\n","# functions to show an image\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","\n","def imshow(img):\n","    # img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","\n","for transforms_compose in transforms_composes_data:\n","    train_data = LontarDataset(transform=transforms.Compose(transforms_compose))\n","    train_loader = DataLoader(dataset=train_data, batch_size=batch_size_train,\n","                          num_workers=num_workers, pin_memory=True, sampler=sampler)\n","    # get some random training images\n","    dataiter = iter(train_loader)\n","    images, labels = dataiter.next()\n","    plt.figure(figsize=(20, 10))\n","\n","    # show images\n","    imshow(torchvision.utils.make_grid(images[0:8, :, :]))\n","    # print labels\n","    print(' '.join('%15s' % classes[labels[j]] for j in range(batch_size_train if batch_size_train < 8 else 10)))"]},{"cell_type":"markdown","metadata":{"_cell_guid":"16af65a5-0b3c-4797-8af2-7910f9f05020","_uuid":"a44f68fd-5ef8-44a7-9997-55d5fc53e802","trusted":true},"source":["# Run Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9b2ec0d-601a-4ea3-905f-f446ef96b05a","_uuid":"1a3f6cb8-b5ff-4edd-be28-f012b9153e0b","collapsed":false,"execution":{"iopub.execute_input":"2022-08-10T10:55:54.889459Z","iopub.status.busy":"2022-08-10T10:55:54.889080Z","iopub.status.idle":"2022-08-10T10:55:54.911776Z","shell.execute_reply":"2022-08-10T10:55:54.910847Z","shell.execute_reply.started":"2022-08-10T10:55:54.889413Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def main():\n","    global arch, half, weight_decay, momentum, lr, start_epoch, epochs, batch_size, evaluate, pretrained, print_freq, save_every, save_dir, best_prec1, best_prec5, avg_time, sum_time, optimizer, lr_scheduler, grayscale, do_normalize, normalize_rgb, normalize_gray\n","    \n","    data = []\n","    losses = []\n","    err1s = []\n","    err5s = []\n","    best_err1s = []\n","    best_err5s = []\n","    \n","    # Check the save_dir exists or not\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","\n","    model = archfunc\n","    model.cuda()\n","\n","    # define loss function (criterion) and optimizer\n","    criterion = nn.CrossEntropyLoss().cuda()\n","\n","    if half:\n","        print('half persicion is used.')\n","        model.half()\n","        criterion.half()\n","\n","    optimizer = torch.optim.SGD(model.parameters(), lr,\n","                                momentum=momentum,\n","                                weight_decay=weight_decay)\n","\n","    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n","                                                        milestones=[100, 150], last_epoch=start_epoch - 1)\n","\n","    if evaluate:\n","        print('evalution mode')\n","        model.load_state_dict(torch.load(os.path.join(save_dir, 'model.th')))\n","        best_prec1, best_prec5 = validate(val_loader, model, criterion)\n","        return best_prec1, best_prec5\n","\n","    if pretrained:\n","        print('evalution of pretrained model')\n","        save_dir = 'pretrained_models'\n","        pretrained_model = arch + '.th'\n","        model.load_state_dict(torch.load(\n","            os.path.join(save_dir, pretrained_model)))\n","        best_prec1, best_prec5 = validate(val_loader, model, criterion)\n","        return best_prec1, best_prec5\n","\n","    # warmup before execution for time measurement\n","    \n","    #print(\"!!! WARMUP PHASE, DOES NOT REFLECT RESULT !!!\")\n","    #train(train_loader, model, criterion, optimizer, 1)\n","    torch.cuda.synchronize()\n","    times = []\n","\n","    # main training program\n","    for epoch in range(start_epoch, epochs):\n","\n","        start_epoch = time.time()\n","\n","        # train for one epoch\n","        print('Training {} model'.format(arch))\n","        print('current lr {:.5e}'.format(optimizer.param_groups[0]['lr']))\n","        data.append(train(train_loader, model, criterion, optimizer, epoch))\n","        losses.append(data[epoch])\n","        \n","        lr_scheduler.step()\n","\n","        end_epoch = time.time()\n","        elapsed = end_epoch - start_epoch\n","        times.append(elapsed)\n","\n","        # evaluate on validation set\n","        prec1, prec5 = validate(val_loader, model, criterion)\n","        err1 = 100-prec1\n","        err5 = 100-prec5\n","\n","        err1s.append(err1)\n","        err5s.append(err5)\n","\n","        # remember best prec@1 and save checkpoint\n","        is_best = prec1 > best_prec1\n","        best_prec1 = max(prec1, best_prec1)\n","        best_prec5 = max(prec5, best_prec5)\n","        best_err1 = 100-prec1\n","        best_err5 = 100-prec5\n","        print('Current Best Prec @1: {best_prec1:.3f} (Err: {best_err1:.3f} ) | '\n","              '@5: {best_prec5:.3f} (Err: {best_err5:.3f} )\\n'\n","              .format(epoch, best_prec1=best_prec1, best_err1=best_err1, best_prec5=best_prec5, best_err5=best_err5))\n","        best_err1s.append(100-best_prec1)\n","        best_err5s.append(100-best_prec5)\n","\n","        if epoch > 0 and epoch % save_every == 0:\n","            save_checkpoint(model.state_dict(), filename=os.path.join(\n","                save_dir, 'checkpoint.th'))\n","        if is_best:\n","            save_checkpoint(model.state_dict(),\n","                            filename=os.path.join(save_dir, 'model.th'))\n","\n","    model.load_state_dict(torch.load(os.path.join(save_dir, 'model.th')))\n","    best_prec1, best_prec5 = validate(val_loader, model, criterion)\n","    \n","    avg_time = sum(times)/epochs\n","    sum_time = sum(times)\n","    \n","    fig, (plt_loss, plt_error) = plt.subplots(1,2,figsize=(20,4))\n","    \n","    plt_loss.plot(losses, 'b-')\n","    plt_loss.set_xlabel('Epochs')\n","    plt_loss.set_ylabel('Loss')\n","    plt_loss.grid(True, 'major', 'both')\n","    \n","    plt_error.plot(err1s, label = \"Error@1\")\n","    plt_error.plot(err5s, label = \"Error@5\")\n","    plt_error.plot(best_err1s, label = \"Best Error@1\")\n","    plt_error.plot(best_err5s, label = \"Best Error@5\")\n","    plt_error.set_ylim([0,100])\n","    plt_error.set_xlabel('Epochs')\n","    plt_error.set_ylabel('Errors')\n","    plt_error.grid(True, 'major', 'both')\n","    \n","    plt.suptitle(arch)\n","    plt.legend(loc=1)\n","    plt.show()\n","    \n","    return best_prec1, best_prec5"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab645df9-dcf7-4494-8489-280a3495dd3b","_uuid":"91959c92-ec10-4db0-8285-0396ff3e4993","collapsed":false,"execution":{"iopub.execute_input":"2022-08-10T10:55:54.914061Z","iopub.status.busy":"2022-08-10T10:55:54.912978Z","iopub.status.idle":"2022-08-10T10:55:55.393947Z","shell.execute_reply":"2022-08-10T10:55:55.392816Z","shell.execute_reply.started":"2022-08-10T10:55:54.914024Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["if __name__ == '__main__':\n","    current_device = torch.cuda.current_device()\n","    device_name = torch.cuda.get_device_name(0)\n","    \n","    best_prec1, best_prec5 = main()\n","    \n","    print(device_name)\n","    print('Training took {} seconds (avg. {} per epoch).\\n'\n","          'The training accuracy from {} model after {} epochs is: \\n'\n","          'Prec@1 = {acc1:.3f}\\n'\n","          'Prec@5 = {acc5:.3f}'.format(\n","           sum_time, avg_time, arch, epochs, acc1 = best_prec1, acc5 = best_prec5))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-08-10T10:55:55.395312Z","iopub.status.idle":"2022-08-10T10:55:55.396178Z","shell.execute_reply":"2022-08-10T10:55:55.395958Z","shell.execute_reply.started":"2022-08-10T10:55:55.395917Z"},"trusted":true},"outputs":[],"source":["import IPython.display as ipd\n","\n","audio_url = \"https://assets.mixkit.co/sfx/download/mixkit-happy-bells-notification-937.wav\"\n","ipd.Audio(audio_url, autoplay=True)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 ('.venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"e289cddceda22f07fd02df22b1c5dd179b3e4cd4d6c1ebd50c3cffbb0decccb1"}}},"nbformat":4,"nbformat_minor":4}
